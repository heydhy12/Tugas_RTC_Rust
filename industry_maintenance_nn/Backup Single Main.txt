use csv::Reader;
use ndarray::{Array, Array1, Array2, Axis};
use ndarray_rand::RandomExt;
use ndarray_rand::rand_distr::Uniform;
use std::fs::File;
use std::error::Error;

// 1) Struktur menyimpan data dari CSV
#[derive(Debug, serde::Deserialize)]
struct Record {
    air_temperature_k: f64,
    process_temperature_k: f64,
    rotational_speed_rpm: f64,
    torque_nm: f64,
    failure_type: String,
}

// 2) Struktur Neural Network dengan 2 Hidden Layer
#[derive(Debug)]
struct NeuralNetwork {
    weights1: Array2<f64>, 
    bias1: Array1<f64>,    
    weights2: Array2<f64>, 
    bias2: Array1<f64>,    
    weights3: Array2<f64>, 
    bias3: Array1<f64>,
}

impl NeuralNetwork {
    // 3) Inisialisasi Neural Network dengan He initialization
    fn new(input_size: usize, hidden_size1: usize, hidden_size2: usize, output_size: usize) -> Self {
        let he_std1 = (2.0 / input_size as f64).sqrt();
        let he_std2 = (2.0 / hidden_size1 as f64).sqrt();
        let he_std3 = (2.0 / hidden_size2 as f64).sqrt();

        let weights1 = Array::random((input_size, hidden_size1), Uniform::new(-he_std1, he_std1));
        let bias1 = Array::zeros(hidden_size1);

        let weights2 = Array::random((hidden_size1, hidden_size2), Uniform::new(-he_std2, he_std2));
        let bias2 = Array::zeros(hidden_size2);

        let weights3 = Array::random((hidden_size2, output_size), Uniform::new(-he_std3, he_std3));
        let bias3 = Array::zeros(output_size);

        NeuralNetwork {
            weights1,
            bias1,
            weights2,
            bias2,
            weights3,
            bias3,
        }
    }

    // 4) Fungsi aktivasi ReLU
    fn relu(x: &Array2<f64>) -> Array2<f64> {
        x.mapv(|v| if v > 0.0 { v } else { 0.0 })
    }

    // 5) Turunan fungsi ReLU
    fn relu_derivative(x: &Array2<f64>) -> Array2<f64> {
        x.mapv(|v| if v > 0.0 { 1.0 } else { 0.0 })
    }

    // 6) Fungsi Softmax untuk output layer
    fn softmax(x: &Array2<f64>) -> Array2<f64> {
        let max_x = x.fold_axis(Axis(1), f64::NEG_INFINITY, |&a, &b| a.max(b));
        let exp_x = (x - &max_x.insert_axis(Axis(1))).mapv(f64::exp);
        let sum_exp_x = exp_x.sum_axis(Axis(1)).insert_axis(Axis(1));
        &exp_x / &sum_exp_x
    }

    // 7) Fungsi Loss (Cross-Entropy)
    fn cross_entropy_loss(y_pred: &Array2<f64>, y_true: &Array2<f64>) -> f64 {
        let epsilon = 1e-10;
        -(y_true * y_pred.mapv(|v| (v + epsilon).ln())).sum()
    }

    // 8) Forward propagation
    fn forward(&self, x: &Array2<f64>) -> Array2<f64> {
        let hidden_input1 = x.dot(&self.weights1) + &self.bias1;
        let hidden_output1 = Self::relu(&hidden_input1);

        let hidden_input2 = hidden_output1.dot(&self.weights2) + &self.bias2;
        let hidden_output2 = Self::relu(&hidden_input2);

        let output_input = hidden_output2.dot(&self.weights3) + &self.bias3;
        Self::softmax(&output_input)
    }

    // 9) Training model dengan Backpropagation
    fn train(&mut self, x: &Array2<f64>, y: &Array2<f64>, learning_rate: f64, epochs: usize) {
        for epoch in 0..epochs {
            // Forward pass
            let hidden_input1 = x.dot(&self.weights1) + &self.bias1;
            let hidden_output1 = Self::relu(&hidden_input1);

            let hidden_input2 = hidden_output1.dot(&self.weights2) + &self.bias2;
            let hidden_output2 = Self::relu(&hidden_input2);

            let output_input = hidden_output2.dot(&self.weights3) + &self.bias3;
            let output = Self::softmax(&output_input);

            // Backward pass
            let output_error = &output - y;
            let hidden_error2 = output_error.dot(&self.weights3.t()) * Self::relu_derivative(&hidden_output2);
            let hidden_error1 = hidden_error2.dot(&self.weights2.t()) * Self::relu_derivative(&hidden_output1);

            // Update weights dan biases
            self.weights3 -= &(learning_rate * hidden_output2.t().dot(&output_error));
            self.bias3 -= &(learning_rate * output_error.sum_axis(Axis(0)));

            self.weights2 -= &(learning_rate * hidden_output1.t().dot(&hidden_error2));
            self.bias2 -= &(learning_rate * hidden_error2.sum_axis(Axis(0)));

            self.weights1 -= &(learning_rate * x.t().dot(&hidden_error1));
            self.bias1 -= &(learning_rate * hidden_error1.sum_axis(Axis(0)));

            // Tampilkan loss setiap 100 epoch
            if epoch % 100 == 0 {
                let loss = Self::cross_entropy_loss(&output, y);
                println!("Epoch: {}, Loss: {}", epoch, loss);
            }
        }
    }
}

fn main() -> Result<(), Box<dyn Error>> {
    // 10) Membaca file CSV
    println!("Membaca file CSV...");
    let file_path = "csv/industry_maintenance.csv";
    let file = File::open(file_path).expect("Gagal membuka file CSV!");
    let mut rdr = Reader::from_reader(file);

    // 11) Parsing data CSV ke dalam vektor records
    let mut records = Vec::new();
    for result in rdr.deserialize() {
        let record: Record = result?;
        records.push(record);
    }

    // 12) Pastikan data berhasil dibaca
    if records.is_empty() {
        eprintln!("Tidak ada data yang dibaca dari file CSV!");
        return Ok(());
    }
    println!("Berhasil membaca {} records.", records.len());

    // 13) Inisialisasi array untuk input (x) dan label (y)
    let mut x = Array2::zeros((records.len(), 4));
    let mut y = Array2::zeros((records.len(), 4));

    // 14) Memasukkan data dari records ke dalam array x dan y
    for (i, record) in records.iter().enumerate() {
        x[[i, 0]] = record.air_temperature_k;
        x[[i, 1]] = record.process_temperature_k;
        x[[i, 2]] = record.rotational_speed_rpm;
        x[[i, 3]] = record.torque_nm;

        // Konversi label failure_type ke one-hot encoding
        match record.failure_type.as_str() {
            "Power Failure" => y[[i, 0]] = 1.0,
            "Overstrain Failure" => y[[i, 1]] = 1.0,
            "No Failure" => y[[i, 2]] = 1.0,
            "Heat Dissipation Failure" => y[[i, 3]] = 1.0,
            _ => (),
        }
    }

    // 15) Normalisasi input menggunakan z-score
    let mean = x.mean_axis(Axis(0)).unwrap();
    let std = x.std_axis(Axis(0), 0.0);
    x = (&x - &mean) / &std;

    // 16) Inisialisasi neural network dengan 2 hidden layer
    println!("Inisialisasi neural network...");
    let input_size = 4;
    let hidden_size1 = 5; 
    let hidden_size2 = 3; 
    let output_size = 4;
    let learning_rate = 0.001; 
    let epochs = 1000;

    let mut nn = NeuralNetwork::new(input_size, hidden_size1, hidden_size2, output_size);

    // 17) Training model
    println!("Memulai training...");
    nn.train(&x, &y, learning_rate, epochs);
    println!("Training selesai!");

    // 18) Evaluasi model
    let predictions = nn.forward(&x);
    let loss = NeuralNetwork::cross_entropy_loss(&predictions, &y);
    println!("Loss akhir: {}", loss);

    // 19) Hitung akurasi
    let correct = predictions
        .rows()
        .into_iter()
        .zip(y.rows().into_iter())
        .filter(|(pred_row, true_row)| {
            // Ambil indeks kelas dengan probabilitas tertinggi sebagai prediksi
            let predicted_class = pred_row
                .iter()
                .enumerate()
                .max_by(|a, b| a.1.partial_cmp(b.1).unwrap())
                .unwrap()
                .0;
            // Ambil indeks kelas yang sebenarnya
            let true_class = true_row
                .iter()
                .enumerate()
                .max_by(|a, b| a.1.partial_cmp(b.1).unwrap())
                .unwrap()
                .0;
            // Bandingkan prediksi dengan kelas sebenarnya
            predicted_class == true_class
        })
        .count();

    // 20) Hitung dan tampilkan akurasi
    let accuracy = correct as f64 / predictions.shape()[0] as f64;
    println!("Akurasi: {:.2}%", accuracy * 100.0);

    Ok(())
}